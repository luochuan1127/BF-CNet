{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "第一部分：模型训练"
      ],
      "metadata": {
        "id": "GFcH2rJ0cz8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Connect to Google Drive"
      ],
      "metadata": {
        "id": "NyjJOK2tUniQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-XeBOFp6rtv",
        "outputId": "9e158d30-5449-4cbd-969f-9248d96c5baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Install the bayesnf library"
      ],
      "metadata": {
        "id": "hrE7CV5kVBc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bayesnf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsEmtG0_6wnb",
        "outputId": "c79a7e4e-5fb6-47dd-93c7-b5833488aecd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesnf\n",
            "  Downloading bayesnf-0.1.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from bayesnf) (0.10.6)\n",
            "Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.12/dist-packages (from bayesnf) (0.5.3)\n",
            "Collecting jaxtyping (from bayesnf)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bayesnf) (2.0.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from bayesnf) (0.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from bayesnf) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-probability>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability[jax]>=0.19.0->bayesnf) (0.25.0)\n",
            "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->bayesnf) (0.5.3)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->bayesnf) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->bayesnf) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->bayesnf) (1.16.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (0.1.9)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (1.1.1)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (0.11.24)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (0.1.76)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->bayesnf) (0.1.10)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->bayesnf)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax->bayesnf) (0.1.90)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->bayesnf) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->bayesnf) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->bayesnf) (2025.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->bayesnf) (75.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->bayesnf) (0.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax->bayesnf) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax->bayesnf) (2.19.2)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow-probability>=0.19.0->tensorflow-probability[jax]>=0.19.0->bayesnf) (1.17.3)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (24.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (4.13.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->bayesnf) (3.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->bayesnf) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->bayesnf) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->bayesnf) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->bayesnf) (3.23.0)\n",
            "Downloading bayesnf-0.1.3-py3-none-any.whl (25 kB)\n",
            "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping, bayesnf\n",
            "Successfully installed bayesnf-0.1.3 jaxtyping-0.3.2 wadler-lindig-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import jax\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bayesnf.spatiotemporal import BayesianNeuralFieldMAP"
      ],
      "metadata": {
        "id": "ZHBsPC2T6yDa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/xlc/input/train_CMEMS_SST.csv', index_col=0, parse_dates=['datetime'])\n",
        "df_train['datetime'] = pd.to_numeric(df_train['datetime'], errors='coerce')\n",
        "df_train['datetime'] = pd.to_datetime(df_train['datetime'], unit='D', origin='1899-12-30')\n",
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42VoFAnH6zny",
        "outputId": "98d790a3-c23f-4bfd-cb95-548fdbe1b56d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242091, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BayesianNeuralFieldMAP(\n",
        "  width=256,\n",
        "  depth=2,\n",
        "  freq='D',\n",
        "  seasonality_periods=['W', 'M'], # week month\n",
        "  num_seasonal_harmonics=[2, 4],\n",
        "  feature_cols=['datetime', 'longitude', 'latitude'],\n",
        "  target_col='sla',\n",
        "  observation_model='NORMAL',\n",
        "  timetype='index',\n",
        "  standardize=['longitude','latitude'],\n",
        "  )"
      ],
      "metadata": {
        "id": "ujOf2lsG605A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import threading\n",
        "import pynvml\n",
        "import jax\n",
        "\n",
        "# Use on-demand GPU memory allocation instead of pre-allocating a large block\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
        "\n",
        "# ------------------- Initialize GPU monitoring -------------------\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # Select GPU 0\n",
        "\n",
        "def monitor_gpu(interval=60):\n",
        "    \"\"\"Background thread: print GPU memory usage every `interval` seconds\"\"\"\n",
        "    while True:\n",
        "        meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "        used = meminfo.used / 1024**3\n",
        "        total = meminfo.total / 1024**3\n",
        "        print(f\"[GPU Memory] {used:.2f} GB / {total:.2f} GB\")\n",
        "        time.sleep(interval)\n",
        "\n",
        "# Start GPU memory monitoring thread\n",
        "monitor_thread = threading.Thread(target=monitor_gpu, args=(60,), daemon=True)\n",
        "monitor_thread.start()\n",
        "\n",
        "# ------------------- Manual training loop -------------------\n",
        "start_time = time.time()\n",
        "\n",
        "model = model.fit(\n",
        "    df_train,\n",
        "    seed=jax.random.PRNGKey(0),  # Random seed\n",
        "    ensemble_size=1,             # Train 1 model at a time\n",
        "    learning_rate=0.005,\n",
        "    num_epochs=5000              # Total number of training epochs\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Total training time:\", end_time - start_time, \"s\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dqd7yh1063v4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533d6717-6239-4f08-dadb-d6870ee5bbf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPU Memory] 0.38 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "[GPU Memory] 1.94 GB / 15.00 GB\n",
            "Total training time: 318.5527732372284 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cloudpickle\n",
        "# save model\n",
        "with open('/content/drive/MyDrive/xlc/model/model_CMEMS_SST.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(model, f)"
      ],
      "metadata": {
        "id": "jXarrT7k6_Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "第二部分：模型加载"
      ],
      "metadata": {
        "id": "Fp4Pf4Mn6_6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "import cloudpickle\n",
        "with open('/content/drive/MyDrive/xlc/model/model_CMEMS_SST.pkl', 'rb') as f:\n",
        "    model = cloudpickle.load(f)"
      ],
      "metadata": {
        "id": "0yb_WEp-7B4-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import test\n",
        "import pandas as pd\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/xlc/input/validation_CMEMS_SST.csv', index_col=0, parse_dates=['datetime'])\n",
        "df_test['datetime'] = pd.to_numeric(df_test['datetime'], errors='coerce')\n",
        "df_test['datetime'] = pd.to_datetime(df_test['datetime'], unit='D', origin='1899-12-30')\n",
        "last_col = df_test.columns[-1]\n",
        "df_test[last_col] = df_test[last_col].fillna(9999)\n",
        "quantiles = list(np.arange(0.01, 1, 0.01))\n",
        "quantiles = tuple(quantiles)\n",
        "yhat, yhat_quantiles = model.predict(df_test, quantiles=quantiles)"
      ],
      "metadata": {
        "id": "yO1WIriV7ELs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f5c811-e22e-4893-fabc-676dc3570585"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPU Memory] 0.38 GB / 15.00 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to matrix\n",
        "yhat_matrix = np.column_stack([q.tolist() for q in yhat_quantiles])\n",
        "gt_matrix = df_test.sla.to_numpy()\n",
        "yhat_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X476YFDt9DTA",
        "outputId": "6fe8c889-83f1-42f8-f820-68ffff9a43df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(360254, 99)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional:\n",
        "# compute MAE to check model performance\n",
        "diff = df_test[last_col] - yhat_matrix[:, 47]\n",
        "# Build mask to exclude points equal to 9999\n",
        "mask = df_test[last_col] != 9999\n",
        "valid_diff = diff[mask]\n",
        "# MAE\n",
        "mae = np.mean(np.abs(valid_diff))\n",
        "print(\"MAE:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rjJkHW0rs1V",
        "outputId": "339df0d5-63bc-4e2d-d584-07b7789e75f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.1588131631405801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save yhat_matrix to CSV\n",
        "output_csv_path = '/content/drive/MyDrive/xlc/output/SSIM_CMEMS_SST (2).csv'\n",
        "\n",
        "# Add column names for easier distinction between different quantiles\n",
        "col_names = [f'Quantile_{q}' for q in quantiles]\n",
        "df_yhat = pd.DataFrame(yhat_matrix, columns=col_names)\n",
        "df_yhat.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"yhat_matrix has been saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "RmZEsUN27ZO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x5ub-0kH8e7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}